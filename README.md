# ğŸš€ Projet M2 Data -- Pipeline ETL DistribuÃ© (NiFi / Kafka / Postgres)

## ğŸ“Œ Contexte

Ce projet consiste Ã  mettre en place une chaÃ®ne complÃ¨te **ETL
distribuÃ©e** en environnement **Docker**, permettant de collecter,
transformer et stocker en quasi temps rÃ©el des **donnÃ©es aÃ©riennes
issues d'API publiques**.\
L'objectif est de dÃ©montrer la capacitÃ© Ã  gÃ©rer un flux de donnÃ©es
massives et Ã  produire des indicateurs exploitables dans un outil de
visualisation.

------------------------------------------------------------------------

## ğŸ§© Architecture globale

``` text
API (OpenSky / AirLabs / OpenAIP)
        â”‚
        â–¼
  [Apache NiFi] â†’ ingestion
        â”‚ (PublishKafkaRecord)
        â–¼
  [Apache Kafka] â†’ streaming distribuÃ©
        â”‚ (Topic: flights_positions)
        â–¼
  [Apache Spark Streaming] â†’ traitement & agrÃ©gation
        â”‚
        â–¼
  [Postgres] â†’ stockage distribuÃ© â†’ Visualisation dans PgAdmin
        â”‚
        â–¼
  [Power BI / Grafana] â†’ visualisation
```

------------------------------------------------------------------------

## âš™ï¸ Technologies utilisÃ©es

  --------------------------------------------------------------------------
  Composant                   RÃ´le             Description
  --------------------------- ---------------- -----------------------------
  **NiFi**                    Ingestion        RÃ©cupÃ©ration pÃ©riodique du
                                               flux (InvokeHTTP), extraction
                                               JSON et publication dans
                                               Kafka

  **Kafka**                   Message broker   Centralise le flux temps rÃ©el
                                               (`flights_positions`)

  **Spark Structured          Traitement       Lecture continue du flux
  Streaming**                                  Kafka, nettoyage, jointures
                                               et calculs

  **Postgres**                Stockage         Base distribuÃ©e pour la
                                               persistance et la
                                               consultation des donnÃ©es
                                               agrÃ©gÃ©es

  **Grafana**                 Visualisation    CrÃ©ation de tableaux de bord
                                               Ã  partir des donnÃ©es stockÃ©es

  **Docker**                  Infrastructure   Orchestration des services
                                               (NiFi, Kafka, Spark,
                                               Postgres, etc.)
  --------------------------------------------------------------------------

------------------------------------------------------------------------

## ğŸ”„ Fonctionnement du pipeline

### 1. **Ingestion -- Apache NiFi**

-   **InvokeHTTP** : appelle l'API (ex. OpenSky) toutes les 10
    secondes.
-   **EvaluateJsonPath** : extrait les champs pertinents.
-   **AttributesToJSON** : reformate les donnÃ©es en JSON.
-   **PublishKafkaRecord_2\_0** : envoie les messages vers le topic
    Kafka `{topic}`.

### 2. **Streaming -- Apache Kafka**

-   Centralise les messages reÃ§us.\

-   VÃ©rification possible via :

    ``` bash
    kafka-console-consumer --bootstrap-server kafka:9092 --topic flights_positions --from-beginning
    ```

### 3. **Traitement -- Apache Spark**

-   Lecture du flux Kafka en temps rÃ©el :

    ``` python
    df = spark.readStream.format("kafka").option("kafka.bootstrap.servers", "kafka:9092").option("subscribe", "flights_positions").load()
    ```

-   Nettoyage et jointure avec tables de rÃ©fÃ©rence (AirLabs / CSV).

-   Calculs typiques :

    -   Nombre de vols actifs par pays.
    -   Vitesse moyenne par zone gÃ©ographique.
    -   DÃ©tection d'altitudes incohÃ©rentes.

### 4. **Stockage -- Postgres**

-   CrÃ©ation des tables **airports, runways, opensky_positions**

-   Ã‰criture depuis Spark

### 5. **Visualisation**

-   Connexion Ã  Postgres (connecteur ODBC / natif).\
-   Exemples :
    -   Carte des positions d'avions (lat/lon).
    -   Graphiques de vitesse moyenne.
    -   Nombre de vols actifs en temps rÃ©el.

------------------------------------------------------------------------

## ğŸ§± Structure du dÃ©pÃ´t

        â”œâ”€â”€ Donnees_Distribuees_Col_Met
        â”‚Â Â  â”œâ”€â”€ grafana
        â”‚Â Â  â”‚Â Â  â””â”€â”€ docker-compose.yml
        â”‚Â Â  â”œâ”€â”€ kafka
        â”‚Â Â  â”‚Â Â  â”œâ”€â”€ docker-compose.yml
        â”‚Â Â  â”‚Â Â  â””â”€â”€ offsetexplorer.sh
        â”‚Â Â  â”œâ”€â”€ modelisation
        â”‚Â Â  â”‚Â Â  â”œâ”€â”€ client.json
        â”‚Â Â  â”‚Â Â  â”œâ”€â”€ clients_compl.csv
        â”‚Â Â  â”‚Â Â  â”œâ”€â”€ docker-compose.yml
        â”‚Â Â  â”‚Â Â  â”œâ”€â”€ drivers
        â”‚Â Â  â”‚Â Â  â”œâ”€â”€ nifi_data
        â”‚Â Â  â”‚Â Â  â””â”€â”€ clients_compl.csv
        â”‚Â Â  â”œâ”€â”€ README.md
        â”‚Â Â  â”œâ”€â”€ spark
        â”‚Â Â  â”‚Â Â  â”œâ”€â”€ docker-compose.yml
        â”‚Â Â  â”‚Â Â  â”œâ”€â”€ dockerfile
        â”‚Â Â  â”‚Â Â  â””â”€â”€ spark-apps
        â”‚Â Â  â”‚Â Â      â”œâ”€â”€ airports_etl.py
        â”‚Â Â  â”‚Â Â      â”œâ”€â”€ airtraffic_etl.py
        â”‚Â Â  â”‚Â Â      â”œâ”€â”€ config
        â”‚Â Â  â”‚Â Â      â”‚Â Â  â”œâ”€â”€ settings_airports.py
        â”‚Â Â  â”‚Â Â      â”‚Â Â  â””â”€â”€ settings_flight_position.py
        â”‚Â Â  â”‚Â Â      â”œâ”€â”€ pipelines
        â”‚Â Â  â”‚Â Â      â”‚Â Â  â”œâ”€â”€ kafka_reader.py
        â”‚Â Â  â”‚Â Â      â”‚Â Â  â”œâ”€â”€ postgres_writer.py
        â”‚Â Â  â”‚Â Â      â”‚Â Â  â””â”€â”€ transformer.py
        â”‚Â Â  â”‚Â Â      â”œâ”€â”€ requirements.txt
        â”‚Â Â  â”‚Â Â      â””â”€â”€ utils
        â”‚Â Â  â”‚Â Â          â”œâ”€â”€ kafka_utils.py
        â”‚Â Â  â”‚Â Â          â”œâ”€â”€ postgres_utils.py
        â”‚Â Â  â”‚Â Â          â””â”€â”€ spark_utils.py
        â”‚Â Â  â””â”€â”€ web
        â”‚Â Â      â”œâ”€â”€ app.py
        â”‚Â Â      â”œâ”€â”€ templates
        â”‚Â Â      â”‚Â Â  â”œâ”€â”€ app.html
        â”‚Â Â      â”‚Â Â  â”œâ”€â”€ dashboard.html
        â”‚Â Â      â”‚Â Â  â”œâ”€â”€ index.html
        â”‚Â Â      â”‚Â Â  â””â”€â”€ layout.html
        â”‚Â Â      â””â”€â”€ utils
        â”‚Â Â          â”œâ”€â”€ db_utils.py
        â”‚Â Â          â””â”€â”€ spark_utils.py

------------------------------------------------------------------------

## â–¶ï¸ Lancement du projet

### 1. Cloner le dÃ©pÃ´t

``` bash
git clone https://github.com/<user>/projet-m2-data.git
cd projet-m2-data
```

### 2. DÃ©marrer l'environnement

``` bash
docker compose up -d
```

### 3. Importer le flux NiFi

-   AccÃ©der Ã  <http://localhost:8080/nifi>
-   Importer `nifi_template.xml`
-   Lancer le flux.

### 4. VÃ©rifier Kafka

``` bash
docker exec -it kafka kafka-topics --list --bootstrap-server kafka:9092
```

### 5. Lancer Spark Streaming

``` bash
docker exec -it spark-master /opt/spark/bin/spark-submit --master spark://spark-master:7077 --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.postgresql:postgresql:42.7.3 --conf spark.driver.extraJavaOptions="-Duser.home=/tmp -Dlog4j.configuration=file:/dev/null" --conf spark.executor.extraJavaOptions="-Duser.home=/tmp" /opt/spark/work-dir/airtraffic_etl.py
```

### 6. Visualiser les rÃ©sultats

-   Se connecter Ã  Cassandra avec / Grafana.\
-   Charger les tables `flights_agg`.

<img width="1690" height="879" alt="image" src="https://github.com/user-attachments/assets/f3559233-305d-4eb9-8f91-8fb2f9532663" />

<img width="1690" height="879" alt="image" src="https://github.com/user-attachments/assets/2b614ff7-408b-4c05-b3ef-72d7fa75d6b2" />



------------------------------------------------------------------------

## ğŸ—ï¸ APIs utilisÃ©es

-   [OpenSky Network](https://opensky-network.org/apidoc)
-   [AirLabs](https://airlabs.co/docsl)
-   [OpenAIP](https://docs.openaip.net)

------------------------------------------------------------------------

## ğŸ§  Auteurs

Projet rÃ©alisÃ© dans le cadre du **Master 2 Data Science**\
**DurÃ©e :** 1 semaine --- **Travail en binÃ´me**
