# ğŸš€ Projet M2 Data -- Pipeline ETL DistribuÃ© (NiFi / Kafka / Cassandra)

## ğŸ“Œ Contexte

Ce projet consiste Ã  mettre en place une chaÃ®ne complÃ¨te **ETL
distribuÃ©e** en environnement **Docker**, permettant de collecter,
transformer et stocker en quasi temps rÃ©el des **donnÃ©es aÃ©riennes
issues d'API publiques**.\
L'objectif est de dÃ©montrer la capacitÃ© Ã  gÃ©rer un flux de donnÃ©es
massives et Ã  produire des indicateurs exploitables dans un outil de
visualisation.

------------------------------------------------------------------------

## ğŸ§© Architecture globale

``` text
API (OpenSky / AirLabs / OpenAIP)
        â”‚
        â–¼
  [Apache NiFi] â†’ ingestion
        â”‚ (PublishKafkaRecord)
        â–¼
  [Apache Kafka] â†’ streaming distribuÃ©
        â”‚ (Topic: flights_positions)
        â–¼
  [Apache Spark Streaming] â†’ traitement & agrÃ©gation
        â”‚
        â–¼
  [Apache Cassandra] â†’ stockage distribuÃ©
        â”‚
        â–¼
  [Power BI / Grafana] â†’ visualisation
```

------------------------------------------------------------------------

## âš™ï¸ Technologies utilisÃ©es

  --------------------------------------------------------------------------
  Composant                   RÃ´le             Description
  --------------------------- ---------------- -----------------------------
  **NiFi**                    Ingestion        RÃ©cupÃ©ration pÃ©riodique du
                                               flux (InvokeHTTP), extraction
                                               JSON et publication dans
                                               Kafka

  **Kafka**                   Message broker   Centralise le flux temps rÃ©el
                                               (`flights_positions`)

  **Spark Structured          Traitement       Lecture continue du flux
  Streaming**                                  Kafka, nettoyage, jointures
                                               et calculs

  **Cassandra**               Stockage         Base distribuÃ©e pour la
                                               persistance et la
                                               consultation des donnÃ©es
                                               agrÃ©gÃ©es

  **Power BI / Grafana**      Visualisation    CrÃ©ation de tableaux de bord
                                               Ã  partir des donnÃ©es stockÃ©es

  **Docker Compose**          Infrastructure   Orchestration des services
                                               (NiFi, Kafka, Spark,
                                               Cassandra, etc.)
  --------------------------------------------------------------------------

------------------------------------------------------------------------

## ğŸ”„ Fonctionnement du pipeline

### 1. **Ingestion -- Apache NiFi**

-   **InvokeHTTP** : appelle l'API (ex. OpenSky) toutes les 10
    secondes.\
-   **EvaluateJsonPath** : extrait les champs pertinents (`timestamp`,
    `icao24`, `lat`, `lon`, `altitude`, `velocity`, etc.).\
-   **AttributesToJSON** : reformate les donnÃ©es en JSON.\
-   **PublishKafkaRecord_2\_0** : envoie les messages vers le topic
    Kafka `flights_positions`.

### 2. **Streaming -- Apache Kafka**

-   Centralise les messages reÃ§us.\

-   VÃ©rification possible via :

    ``` bash
    kafka-console-consumer --bootstrap-server kafka:9092 --topic flights_positions --from-beginning
    ```

### 3. **Traitement -- Apache Spark**

-   Lecture du flux Kafka en temps rÃ©el :

    ``` python
    df = spark       .readStream       .format("kafka")       .option("kafka.bootstrap.servers", "kafka:9092")       .option("subscribe", "flights_positions")       .load()
    ```

-   Nettoyage et jointure avec tables de rÃ©fÃ©rence (AirLabs / CSV).

-   Calculs typiques :

    -   Nombre de vols actifs par pays.
    -   Vitesse moyenne par zone gÃ©ographique.
    -   DÃ©tection d'altitudes incohÃ©rentes.

### 4. **Stockage -- Apache Cassandra**

-   CrÃ©ation d'une **keyspace** et d'une **table flights_agg** :

    ``` sql
    CREATE KEYSPACE flights WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1};
    CREATE TABLE flights.flights_agg (
        flight_id text PRIMARY KEY,
        country text,
        avg_speed float,
        altitude int,
        timestamp timestamp
    );
    ```

-   Ã‰criture depuis Spark :

    ``` python
    df.writeStream     .format("org.apache.spark.sql.cassandra")     .option("keyspace", "flights")     .option("table", "flights_agg")     .start()
    ```

### 5. **Visualisation**

-   Connexion Ã  Cassandra (connecteur ODBC / natif).\
-   Exemples :
    -   Carte des positions d'avions (lat/lon).
    -   Graphiques de vitesse moyenne.
    -   Nombre de vols actifs en temps rÃ©el.

------------------------------------------------------------------------

## ğŸ§± Structure du dÃ©pÃ´t

    ğŸ“ projet-m2-data/
    â”œâ”€â”€ docker-compose.yml
    â”œâ”€â”€ nifi_template.xml
    â”œâ”€â”€ spark/
    â”‚   â”œâ”€â”€ stream_processing.py
    â”‚   â””â”€â”€ requirements.txt
    â”œâ”€â”€ cassandra/
    â”‚   â”œâ”€â”€ init.cql
    â”‚   â””â”€â”€ config/
    â”œâ”€â”€ docs/
    â”‚   â”œâ”€â”€ architecture.png
    â”‚   â””â”€â”€ notes.md
    â””â”€â”€ README.md

------------------------------------------------------------------------

## â–¶ï¸ Lancement du projet

### 1. Cloner le dÃ©pÃ´t

``` bash
git clone https://github.com/<user>/projet-m2-data.git
cd projet-m2-data
```

### 2. DÃ©marrer l'environnement

``` bash
docker compose up -d
```

### 3. Importer le flux NiFi

-   AccÃ©der Ã  <http://localhost:8080/nifi>
-   Importer `nifi_template.xml`
-   Lancer le flux.

### 4. VÃ©rifier Kafka

``` bash
docker exec -it kafka kafka-topics --list --bootstrap-server kafka:9092
```

### 5. Lancer Spark Streaming

``` bash
docker exec -it spark-master spark-submit /opt/spark/app/stream_processing.py
```

### 6. Visualiser les rÃ©sultats

-   Se connecter Ã  Cassandra avec Power BI / Grafana.\
-   Charger les tables `flights_agg`.

------------------------------------------------------------------------

## ğŸ—ï¸ APIs utilisÃ©es

-   [OpenSky Network](https://opensky-network.org/apidoc)
-   [AirLabs](https://airlabs.co/docsl)
-   [OpenAIP](https://docs.openaip.net)

------------------------------------------------------------------------

## ğŸ§  Auteurs

Projet rÃ©alisÃ© dans le cadre du **Master 2 Data Science**\
**DurÃ©e :** 1 semaine --- **Travail en binÃ´me**
